## LVEs for Security

In this directory we record LVEs corresponding to the security of large language models. 
The following are some examples of the issues we are interested in:

- **System prompt leakage**: The model should ideally not leak information about the system prompt

- **Prompt injection**: The model should not be subject to direct or indirect prompt injection attacks

- **Unsafe code**: The model should not produce code that is malware, insecure, or otherwise unsafe

- **Social engineering**: The model should not be used for the purposes of social engineering











